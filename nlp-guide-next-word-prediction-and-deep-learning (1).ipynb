{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "This guide will cover the basics of deep learning for NLP tasks. We will first cover classification of data as spam/not-spam using various deep learing frameworks like RNNs and LSTMs. We will then also cover how to predict the next word in a given word-sequence using RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:59:57.515186Z",
     "iopub.status.busy": "2021-07-15T15:59:57.514815Z",
     "iopub.status.idle": "2021-07-15T15:59:57.519541Z",
     "shell.execute_reply": "2021-07-15T15:59:57.518594Z",
     "shell.execute_reply.started": "2021-07-15T15:59:57.515155Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:06:12.529780Z",
     "iopub.status.busy": "2021-07-15T16:06:12.529293Z",
     "iopub.status.idle": "2021-07-15T16:06:12.534522Z",
     "shell.execute_reply": "2021-07-15T16:06:12.533779Z",
     "shell.execute_reply.started": "2021-07-15T16:06:12.529748Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:58:45.208382Z",
     "iopub.status.busy": "2021-07-15T15:58:45.207762Z",
     "iopub.status.idle": "2021-07-15T15:58:45.217457Z",
     "shell.execute_reply": "2021-07-15T15:58:45.216433Z",
     "shell.execute_reply.started": "2021-07-15T15:58:45.208327Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import collections\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "tokenizer = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:35:56.658703Z",
     "iopub.status.busy": "2021-07-15T15:35:56.658005Z",
     "iopub.status.idle": "2021-07-15T15:36:03.031792Z",
     "shell.execute_reply": "2021-07-15T15:36:03.030619Z",
     "shell.execute_reply.started": "2021-07-15T15:35:56.658665Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, LSTM, Embedding,Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D, SimpleRNN\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints,optimizers, layers\n",
    "from keras.layers import Dense, Input, Flatten, Dropout,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.033812Z",
     "iopub.status.busy": "2021-07-15T15:36:03.033518Z",
     "iopub.status.idle": "2021-07-15T15:36:03.048854Z",
     "shell.execute_reply": "2021-07-15T15:36:03.048123Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.033784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sms-spam-collection-dataset/spam.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text classification using deep learning</h2>\n",
    "\n",
    "Our main objective here is to build a text classifier using neural networks. The basic NLP pipeline will be the same, followed by a new process of building deep learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.051340Z",
     "iopub.status.busy": "2021-07-15T15:36:03.050875Z",
     "iopub.status.idle": "2021-07-15T15:36:03.122502Z",
     "shell.execute_reply": "2021-07-15T15:36:03.121298Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.051293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data and checking it out\n",
    "df = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.124871Z",
     "iopub.status.busy": "2021-07-15T15:36:03.124533Z",
     "iopub.status.idle": "2021-07-15T15:36:03.132194Z",
     "shell.execute_reply": "2021-07-15T15:36:03.130669Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.124840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.134422Z",
     "iopub.status.busy": "2021-07-15T15:36:03.133900Z",
     "iopub.status.idle": "2021-07-15T15:36:03.150444Z",
     "shell.execute_reply": "2021-07-15T15:36:03.149196Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.134387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.152546Z",
     "iopub.status.busy": "2021-07-15T15:36:03.151956Z",
     "iopub.status.idle": "2021-07-15T15:36:03.176298Z",
     "shell.execute_reply": "2021-07-15T15:36:03.175142Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.152510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting required columns\n",
    "df = df[['v1', 'v2']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.179662Z",
     "iopub.status.busy": "2021-07-15T15:36:03.179082Z",
     "iopub.status.idle": "2021-07-15T15:36:03.190560Z",
     "shell.execute_reply": "2021-07-15T15:36:03.189579Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.179628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df.rename(columns={'v1':'label', 'v2':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.193512Z",
     "iopub.status.busy": "2021-07-15T15:36:03.192878Z",
     "iopub.status.idle": "2021-07-15T15:36:03.211992Z",
     "shell.execute_reply": "2021-07-15T15:36:03.210710Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.193475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.214201Z",
     "iopub.status.busy": "2021-07-15T15:36:03.213468Z",
     "iopub.status.idle": "2021-07-15T15:36:03.232780Z",
     "shell.execute_reply": "2021-07-15T15:36:03.231301Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.214156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: text, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.234901Z",
     "iopub.status.busy": "2021-07-15T15:36:03.234459Z",
     "iopub.status.idle": "2021-07-15T15:36:03.468345Z",
     "shell.execute_reply": "2021-07-15T15:36:03.467092Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.234868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go jurong point, crazy.. Available bugis n gre...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3            U dun say early hor... U c already say...\n",
       "4              Nah think goes usf, lives around though\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop words and converting it all to lowercase\n",
    "stop = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x.lower() not in stop))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.470817Z",
     "iopub.status.busy": "2021-07-15T15:36:03.470346Z",
     "iopub.status.idle": "2021-07-15T15:36:03.505166Z",
     "shell.execute_reply": "2021-07-15T15:36:03.503939Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.470770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point, crazy.. available bugis n gre...\n",
       "1                        ok lar... joking wif u oni...\n",
       "2    free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3            u dun say early hor... u c already say...\n",
       "4              nah think goes usf, lives around though\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to lowercase\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.506629Z",
     "iopub.status.busy": "2021-07-15T15:36:03.506287Z",
     "iopub.status.idle": "2021-07-15T15:36:03.540709Z",
     "shell.execute_reply": "2021-07-15T15:36:03.539928Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.506597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazy available bugis n great ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3                  u dun say early hor u c already say\n",
       "4               nah think goes usf lives around though\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing symbols\n",
    "df['text'] = df['text'].apply(lambda x:re.sub('[!@#$:).;,?&]', \"\", x.lower()))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.542145Z",
     "iopub.status.busy": "2021-07-15T15:36:03.541730Z",
     "iopub.status.idle": "2021-07-15T15:36:03.551195Z",
     "shell.execute_reply": "2021-07-15T15:36:03.550227Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.542113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.552841Z",
     "iopub.status.busy": "2021-07-15T15:36:03.552538Z",
     "iopub.status.idle": "2021-07-15T15:36:03.567106Z",
     "shell.execute_reply": "2021-07-15T15:36:03.566012Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.552812Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can give only two arguments if we're working with a dataframe\n",
    "training, testing = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.569087Z",
     "iopub.status.busy": "2021-07-15T15:36:03.568704Z",
     "iopub.status.idle": "2021-07-15T15:36:03.578792Z",
     "shell.execute_reply": "2021-07-15T15:36:03.577883Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.569026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 2)\n",
      "(1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape)\n",
    "print(testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.581181Z",
     "iopub.status.busy": "2021-07-15T15:36:03.580750Z",
     "iopub.status.idle": "2021-07-15T15:36:03.598591Z",
     "shell.execute_reply": "2021-07-15T15:36:03.597257Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.581147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding max sentence length - 300\n",
    "np.max(df['text'].apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.600440Z",
     "iopub.status.busy": "2021-07-15T15:36:03.600119Z",
     "iopub.status.idle": "2021-07-15T15:36:03.604767Z",
     "shell.execute_reply": "2021-07-15T15:36:03.603759Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.600402Z"
    }
   },
   "outputs": [],
   "source": [
    "# We will take the top 200000 frequently occuring words\n",
    "words = 20000\n",
    "tokenizer = Tokenizer(num_words=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit_on_texts` - Updates internal vocabulary based on a list of texts. This method creates the vocabulary index based on word frequency. So if you give it something like, \"The cat sat on the mat.\" It will create a dictionary s.t. `word_index[\"the\"] = 1; word_index[\"cat\"] = 2` it is word -> index dictionary so every word gets a unique integer value. 0 is reserved for padding. So lower integer means more frequent word (often the first few are stop words because they appear a lot). Through num_words, we are picking the most frequent words i.e. the ones with the lower integer values.\n",
    "\n",
    "`texts_to_sequences` Transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary. Nothing more, nothing less, certainly no magic involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.606996Z",
     "iopub.status.busy": "2021-07-15T15:36:03.606224Z",
     "iopub.status.idle": "2021-07-15T15:36:03.711264Z",
     "shell.execute_reply": "2021-07-15T15:36:03.710215Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.606941Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(training.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.712849Z",
     "iopub.status.busy": "2021-07-15T15:36:03.712540Z",
     "iopub.status.idle": "2021-07-15T15:36:03.812931Z",
     "shell.execute_reply": "2021-07-15T15:36:03.811928Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.712816Z"
    }
   },
   "outputs": [],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(training.text)\n",
    "test_seq = tokenizer.texts_to_sequences(testing.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.815590Z",
     "iopub.status.busy": "2021-07-15T15:36:03.815156Z",
     "iopub.status.idle": "2021-07-15T15:36:03.820090Z",
     "shell.execute_reply": "2021-07-15T15:36:03.819074Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.815546Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.821432Z",
     "iopub.status.busy": "2021-07-15T15:36:03.821145Z",
     "iopub.status.idle": "2021-07-15T15:36:03.836023Z",
     "shell.execute_reply": "2021-07-15T15:36:03.835167Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.821403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u': 1, 'call': 2, '2': 3, 'get': 4, \"i'm\": 5, 'ur': 6, '4': 7, 'ltgt': 8, 'go': 9, 'ok': 10, 'free': 11, 'know': 12, 'good': 13, 'come': 14, 'like': 15, 'got': 16, 'now': 17, 'day': 18, 'time': 19, 'send': 20, 'you': 21, 'love': 22, 'want': 23, 'text': 24, 'home': 25, 'going': 26, 'one': 27, \"i'll\": 28, 'see': 29, 'me': 30, 'lor': 31, 'need': 32, 'txt': 33, 'r': 34, 'still': 35, 'today': 36, 'stop': 37, 'sorry': 38, 'later': 39, 'back': 40, 'dont': 41, 'n': 42, 'it': 43, 'tell': 44, 'think': 45, 'new': 46, 'da': 47, 'hi': 48, 'take': 49, 'phone': 50}\n",
      "\n",
      "Found 8470 unique tokens \n"
     ]
    }
   ],
   "source": [
    "# Dictionary for the words and the index\n",
    "word_index = tokenizer.word_index\n",
    "print(dict(itertools.islice(word_index.items(), 50)))\n",
    "print()\n",
    "print('Found %s unique tokens '%len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pad_sequences` is used to ensure that all sequences in a list have the same length. By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.\n",
    "Sequences longer than num_timesteps are truncated so that they fit the desired length.\n",
    "The position where padding or truncation happens is determined by the arguments padding and truncating, respectively. Pre-padding or removing values from the beginning of the sequence is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.841687Z",
     "iopub.status.busy": "2021-07-15T15:36:03.841365Z",
     "iopub.status.idle": "2021-07-15T15:36:03.897481Z",
     "shell.execute_reply": "2021-07-15T15:36:03.896307Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.841657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Padding data for equal lengths, for our models\n",
    "training_data = pad_sequences(train_seq, maxlen=300)\n",
    "testing_data = pad_sequences(test_seq, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.899457Z",
     "iopub.status.busy": "2021-07-15T15:36:03.899143Z",
     "iopub.status.idle": "2021-07-15T15:36:03.904561Z",
     "shell.execute_reply": "2021-07-15T15:36:03.903583Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.899427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 300)\n",
      "(1115, 300)\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.906782Z",
     "iopub.status.busy": "2021-07-15T15:36:03.906262Z",
     "iopub.status.idle": "2021-07-15T15:36:03.919840Z",
     "shell.execute_reply": "2021-07-15T15:36:03.918370Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.906731Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = training['label']\n",
    "y_test = testing['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.921987Z",
     "iopub.status.busy": "2021-07-15T15:36:03.921567Z",
     "iopub.status.idle": "2021-07-15T15:36:03.935454Z",
     "shell.execute_reply": "2021-07-15T15:36:03.934295Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.921942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.937168Z",
     "iopub.status.busy": "2021-07-15T15:36:03.936860Z",
     "iopub.status.idle": "2021-07-15T15:36:03.949617Z",
     "shell.execute_reply": "2021-07-15T15:36:03.948852Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.937139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.951047Z",
     "iopub.status.busy": "2021-07-15T15:36:03.950625Z",
     "iopub.status.idle": "2021-07-15T15:36:03.962184Z",
     "shell.execute_reply": "2021-07-15T15:36:03.961196Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.951002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.963835Z",
     "iopub.status.busy": "2021-07-15T15:36:03.963341Z",
     "iopub.status.idle": "2021-07-15T15:36:03.979027Z",
     "shell.execute_reply": "2021-07-15T15:36:03.978135Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.963803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.983488Z",
     "iopub.status.busy": "2021-07-15T15:36:03.982760Z",
     "iopub.status.idle": "2021-07-15T15:36:03.994420Z",
     "shell.execute_reply": "2021-07-15T15:36:03.993239Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.983447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor (4457, 300)\n",
      "Shape of label tensors (training) (4457, 2)\n",
      "Shape of label tensors (testing) (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "# Converting the labels to categorical\n",
    "# To pass through our model\n",
    "y_train_cat = to_categorical(np.asarray(y_train))\n",
    "y_test_cat = to_categorical(np.asarray(y_test))\n",
    "print('Shape of data tensor', training_data.shape)\n",
    "print('Shape of label tensors (training)', y_train_cat.shape)\n",
    "print('Shape of label tensors (testing)', y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:03.996450Z",
     "iopub.status.busy": "2021-07-15T15:36:03.996007Z",
     "iopub.status.idle": "2021-07-15T15:36:04.011478Z",
     "shell.execute_reply": "2021-07-15T15:36:04.009992Z",
     "shell.execute_reply.started": "2021-07-15T15:36:03.996406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:04.013628Z",
     "iopub.status.busy": "2021-07-15T15:36:04.013014Z",
     "iopub.status.idle": "2021-07-15T15:36:04.021666Z",
     "shell.execute_reply": "2021-07-15T15:36:04.020263Z",
     "shell.execute_reply.started": "2021-07-15T15:36:04.013583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining our embedding dimension\n",
    "embeds = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model building and predicting</h2>\n",
    "\n",
    "We are building the models using different deep learning approaches\n",
    "like CNN, RNN, LSTM, and Bidirectional LSTM and comparing the\n",
    "performance of each model using different accuracy metrics.\n",
    "We can now define our CNN model.\n",
    "Here we define a single hidden layer with 128 memory units. The\n",
    "network uses a dropout with a probability of 0.5. The output layer is a\n",
    "dense layer using the softmax activation function to output a probability\n",
    "prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:04.023998Z",
     "iopub.status.busy": "2021-07-15T15:36:04.023572Z",
     "iopub.status.idle": "2021-07-15T15:36:04.264740Z",
     "shell.execute_reply": "2021-07-15T15:36:04.263936Z",
     "shell.execute_reply.started": "2021-07-15T15:36:04.023961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN 1D model\n"
     ]
    }
   ],
   "source": [
    "print('Training CNN 1D model')\n",
    "model = Sequential()\n",
    "# 20000 was our maximum word number in the tokenizer\n",
    "model.add(Embedding(20000,\n",
    " embeds,\n",
    " input_length=300\n",
    " ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    " optimizer='rmsprop',\n",
    " metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:04.266399Z",
     "iopub.status.busy": "2021-07-15T15:36:04.265878Z",
     "iopub.status.idle": "2021-07-15T15:36:58.480666Z",
     "shell.execute_reply": "2021-07-15T15:36:58.479826Z",
     "shell.execute_reply.started": "2021-07-15T15:36:04.266339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 164ms/step - loss: 0.7082 - acc: 0.6759 - val_loss: 1.0129 - val_acc: 0.8556\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 10s 145ms/step - loss: 0.2377 - acc: 0.9109 - val_loss: 1.1023 - val_acc: 0.8556\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 10s 145ms/step - loss: 0.0956 - acc: 0.9694 - val_loss: 0.6393 - val_acc: 0.8556\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 10s 150ms/step - loss: 0.0625 - acc: 0.9844 - val_loss: 0.3279 - val_acc: 0.8556\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 10s 146ms/step - loss: 0.0391 - acc: 0.9897 - val_loss: 0.3846 - val_acc: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd55b1a6ad0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data, y_train_cat, batch_size=64, epochs=5, validation_data = (testing_data, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:58.482658Z",
     "iopub.status.busy": "2021-07-15T15:36:58.482097Z",
     "iopub.status.idle": "2021-07-15T15:36:59.281703Z",
     "shell.execute_reply": "2021-07-15T15:36:59.280173Z",
     "shell.execute_reply.started": "2021-07-15T15:36:58.482622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7227747 , 0.27722535],\n",
       "       [0.7149998 , 0.28500015],\n",
       "       [0.7137979 , 0.2862021 ],\n",
       "       ...,\n",
       "       [0.733541  , 0.26645893],\n",
       "       [0.7143932 , 0.2856068 ],\n",
       "       [0.7145982 , 0.2854018 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted=model.predict(testing_data)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:59.284738Z",
     "iopub.status.busy": "2021-07-15T15:36:59.284172Z",
     "iopub.status.idle": "2021-07-15T15:36:59.316914Z",
     "shell.execute_reply": "2021-07-15T15:36:59.315884Z",
     "shell.execute_reply.started": "2021-07-15T15:36:59.284702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.9334638 1.       ]\n",
      "recall: [1.         0.57763975]\n",
      "fscore: [0.96558704 0.73228346]\n",
      "support: [954 161]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       954\n",
      "           1       1.00      0.58      0.73       161\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1115\n",
      "   macro avg       0.97      0.79      0.85      1115\n",
      "weighted avg       0.94      0.94      0.93      1115\n",
      " samples avg       0.94      0.94      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "precision, recall, fscore, support = score(y_test_cat,predicted.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(y_test_cat,predicted.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>RNN model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:36:59.319059Z",
     "iopub.status.busy": "2021-07-15T15:36:59.318528Z",
     "iopub.status.idle": "2021-07-15T15:38:50.459842Z",
     "shell.execute_reply": "2021-07-15T15:38:50.459112Z",
     "shell.execute_reply.started": "2021-07-15T15:36:59.319001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SIMPLERNN model.\n",
      "Epoch 1/5\n",
      "279/279 [==============================] - 25s 86ms/step - loss: 0.5212 - accuracy: 0.8645 - val_loss: 0.3486 - val_accuracy: 0.9291\n",
      "Epoch 2/5\n",
      "279/279 [==============================] - 22s 79ms/step - loss: 0.2484 - accuracy: 0.9798 - val_loss: 0.2592 - val_accuracy: 0.9381\n",
      "Epoch 3/5\n",
      "279/279 [==============================] - 21s 77ms/step - loss: 0.1405 - accuracy: 0.9925 - val_loss: 0.2158 - val_accuracy: 0.9426\n",
      "Epoch 4/5\n",
      "279/279 [==============================] - 22s 77ms/step - loss: 0.0834 - accuracy: 0.9974 - val_loss: 0.1945 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "279/279 [==============================] - 21s 75ms/step - loss: 0.0578 - accuracy: 0.9980 - val_loss: 0.1821 - val_accuracy: 0.9408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd55b12ea50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training SIMPLERNN model.')\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000,\n",
    " embeds,\n",
    " input_length=300\n",
    " ))\n",
    "model.add(SimpleRNN(2, input_shape=(None,1)))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(training_data, y_train_cat,\n",
    " batch_size=16,\n",
    " epochs=5,\n",
    " validation_data=(testing_data, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:38:50.461464Z",
     "iopub.status.busy": "2021-07-15T15:38:50.461191Z",
     "iopub.status.idle": "2021-07-15T15:38:51.179657Z",
     "shell.execute_reply": "2021-07-15T15:38:51.178580Z",
     "shell.execute_reply.started": "2021-07-15T15:38:50.461438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9948907e-01, 5.1089545e-04],\n",
       "       [9.9779910e-01, 2.2008889e-03],\n",
       "       [9.9943000e-01, 5.7000760e-04],\n",
       "       ...,\n",
       "       [9.9918503e-01, 8.1497722e-04],\n",
       "       [9.9882549e-01, 1.1744860e-03],\n",
       "       [9.9968708e-01, 3.1298236e-04]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities\n",
    "predicted_Srnn=model.predict(testing_data)\n",
    "predicted_Srnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:38:51.181331Z",
     "iopub.status.busy": "2021-07-15T15:38:51.180977Z",
     "iopub.status.idle": "2021-07-15T15:38:51.209412Z",
     "shell.execute_reply": "2021-07-15T15:38:51.208589Z",
     "shell.execute_reply.started": "2021-07-15T15:38:51.181301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.95213849 0.85714286]\n",
      "recall: [0.98008386 0.70807453]\n",
      "fscore: [0.96590909 0.7755102 ]\n",
      "support: [954 161]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       954\n",
      "           1       0.86      0.71      0.78       161\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1115\n",
      "   macro avg       0.90      0.84      0.87      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      " samples avg       0.94      0.94      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test_cat, predicted_Srnn.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(y_test_cat,predicted_Srnn.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSTM model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:38:51.210924Z",
     "iopub.status.busy": "2021-07-15T15:38:51.210412Z",
     "iopub.status.idle": "2021-07-15T15:41:37.539078Z",
     "shell.execute_reply": "2021-07-15T15:41:37.538137Z",
     "shell.execute_reply.started": "2021-07-15T15:38:51.210887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model.\n",
      "Epoch 1/5\n",
      "279/279 [==============================] - 35s 119ms/step - loss: 0.2705 - accuracy: 0.9005 - val_loss: 0.6849 - val_accuracy: 0.4036\n",
      "Epoch 2/5\n",
      "279/279 [==============================] - 32s 116ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 0.0613 - val_accuracy: 0.9776\n",
      "Epoch 3/5\n",
      "279/279 [==============================] - 33s 120ms/step - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.0796 - val_accuracy: 0.9812\n",
      "Epoch 4/5\n",
      "279/279 [==============================] - 33s 118ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.0765 - val_accuracy: 0.9839\n",
      "Epoch 5/5\n",
      "279/279 [==============================] - 33s 118ms/step - loss: 9.8132e-04 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5419936d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training LSTM model.')\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000,\n",
    " embeds,\n",
    " input_length=300\n",
    " ))\n",
    "model.add(LSTM(16, activation='relu',return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(training_data, y_train_cat,\n",
    " batch_size=16,\n",
    " epochs=5,\n",
    " validation_data=(testing_data, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:41:37.540659Z",
     "iopub.status.busy": "2021-07-15T15:41:37.540374Z",
     "iopub.status.idle": "2021-07-15T15:41:38.595266Z",
     "shell.execute_reply": "2021-07-15T15:41:38.594084Z",
     "shell.execute_reply.started": "2021-07-15T15:41:37.540633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.1004146e-09],\n",
       "       [1.0000000e+00, 1.4025856e-16],\n",
       "       [9.9999952e-01, 4.7674393e-07],\n",
       "       ...,\n",
       "       [1.0000000e+00, 2.9936931e-23],\n",
       "       [1.0000000e+00, 1.5904758e-11],\n",
       "       [1.0000000e+00, 9.1839727e-09]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lstm=model.predict(testing_data)\n",
    "predicted_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:41:38.597066Z",
     "iopub.status.busy": "2021-07-15T15:41:38.596565Z",
     "iopub.status.idle": "2021-07-15T15:41:38.850637Z",
     "shell.execute_reply": "2021-07-15T15:41:38.849555Z",
     "shell.execute_reply.started": "2021-07-15T15:41:38.597002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98553719 1.        ]\n",
      "recall: [1.         0.91304348]\n",
      "fscore: [0.99271592 0.95454545]\n",
      "support: [954 161]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       954\n",
      "           1       1.00      0.91      0.95       161\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.99      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      " samples avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test_cat, predicted_lstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(y_test_cat,predicted_lstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bidirectional LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:41:38.852337Z",
     "iopub.status.busy": "2021-07-15T15:41:38.851993Z",
     "iopub.status.idle": "2021-07-15T15:46:48.674976Z",
     "shell.execute_reply": "2021-07-15T15:46:48.674022Z",
     "shell.execute_reply.started": "2021-07-15T15:41:38.852305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bidirectional LSTM model.\n",
      "Epoch 1/3\n",
      "279/279 [==============================] - 107s 365ms/step - loss: 0.3279 - accuracy: 0.9043 - val_loss: 0.0562 - val_accuracy: 0.9821\n",
      "Epoch 2/3\n",
      "279/279 [==============================] - 100s 360ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0495 - val_accuracy: 0.9839\n",
      "Epoch 3/3\n",
      "279/279 [==============================] - 102s 365ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0512 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd528472b50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Bidirectional LSTM model.')\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000,\n",
    " embeds,\n",
    " input_length=300\n",
    " ))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "model.add(Conv1D(16, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(training_data, y_train_cat,\n",
    " batch_size=16,\n",
    " epochs=3,\n",
    " validation_data=(testing_data, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:46:48.676737Z",
     "iopub.status.busy": "2021-07-15T15:46:48.676298Z",
     "iopub.status.idle": "2021-07-15T15:46:50.979502Z",
     "shell.execute_reply": "2021-07-15T15:46:50.978526Z",
     "shell.execute_reply.started": "2021-07-15T15:46:48.676704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.4269067e-11],\n",
       "       [1.0000000e+00, 1.4120646e-11],\n",
       "       [1.0000000e+00, 3.2728870e-08],\n",
       "       ...,\n",
       "       [1.0000000e+00, 1.6519794e-11],\n",
       "       [1.0000000e+00, 1.0365188e-11],\n",
       "       [1.0000000e+00, 3.4784989e-08]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_blstm=model.predict(testing_data)\n",
    "predicted_blstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:46:50.981159Z",
     "iopub.status.busy": "2021-07-15T15:46:50.980713Z",
     "iopub.status.idle": "2021-07-15T15:46:51.005370Z",
     "shell.execute_reply": "2021-07-15T15:46:51.004266Z",
     "shell.execute_reply.started": "2021-07-15T15:46:50.981120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98651452 0.98013245]\n",
      "recall: [0.99685535 0.91925466]\n",
      "fscore: [0.99165798 0.94871795]\n",
      "support: [954 161]\n",
      "############################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       954\n",
      "           1       0.98      0.92      0.95       161\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      " samples avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(y_test_cat, predicted_blstm.round())\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print(\"############################\")\n",
    "print(sklearn.metrics.classification_report(y_test_cat,predicted_blstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Next word prediction</h2>\n",
    "\n",
    "Mechanisms such as autofills can help us understand the potential sequence of words that can be filled in front of an incomplete sentence. This technique is leveraged in different formats, mostly for email writing.\n",
    "\n",
    "We will build an LSTM model to learn sequences of data from our spam texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:57:41.822837Z",
     "iopub.status.busy": "2021-07-15T15:57:41.822464Z",
     "iopub.status.idle": "2021-07-15T15:57:41.834061Z",
     "shell.execute_reply": "2021-07-15T15:57:41.832800Z",
     "shell.execute_reply.started": "2021-07-15T15:57:41.822806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  go jurong point crazy available bugis n great ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   ham                u dun say early hor u c already say\n",
       "4   ham             nah think goes usf lives around though"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:58:26.159282Z",
     "iopub.status.busy": "2021-07-15T15:58:26.158678Z",
     "iopub.status.idle": "2021-07-15T15:58:26.166409Z",
     "shell.execute_reply": "2021-07-15T15:58:26.165677Z",
     "shell.execute_reply.started": "2021-07-15T15:58:26.159233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
       " 'ok lar joking wif u oni',\n",
       " \"free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry question(std txt ratetc's apply 08452810075over18's\",\n",
       " 'u dun say early hor u c already say',\n",
       " 'nah think goes usf lives around though',\n",
       " \"freemsg hey darling 3 week's word back i'd like fun still tb ok xxx std chgs send å£150 rcv\",\n",
       " 'even brother like speak me treat like aids patent',\n",
       " \"per request 'melle melle (oru minnaminunginte nurungu vettam' set callertune callers press *9 copy friends callertune\",\n",
       " 'winner valued network customer selected receivea å£900 prize reward claim call 09061701461 claim code kl341 valid 12 hours only',\n",
       " 'mobile 11 months more u r entitled update latest colour mobiles camera free call mobile update co free 08002986030']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listing = df.text.tolist()\n",
    "df_listing[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:00:01.988474Z",
     "iopub.status.busy": "2021-07-15T16:00:01.988088Z",
     "iopub.status.idle": "2021-07-15T16:00:01.993402Z",
     "shell.execute_reply": "2021-07-15T16:00:01.992619Z",
     "shell.execute_reply.started": "2021-07-15T16:00:01.988435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the given list to strings\n",
    "from collections import Iterable\n",
    "\n",
    "def reduce_dims(items):\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            for sub_x in reduce_dims(x):\n",
    "                yield sub_x\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:01:35.506498Z",
     "iopub.status.busy": "2021-07-15T16:01:35.506125Z",
     "iopub.status.idle": "2021-07-15T16:01:35.511026Z",
     "shell.execute_reply": "2021-07-15T16:01:35.510006Z",
     "shell.execute_reply.started": "2021-07-15T16:01:35.506466Z"
    }
   },
   "outputs": [],
   "source": [
    "string_final = ''.join(df_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:01:53.742292Z",
     "iopub.status.busy": "2021-07-15T16:01:53.741693Z",
     "iopub.status.idle": "2021-07-15T16:01:53.748972Z",
     "shell.execute_reply": "2021-07-15T16:01:53.748158Z",
     "shell.execute_reply.started": "2021-07-15T16:01:53.742241Z"
    }
   },
   "outputs": [],
   "source": [
    "string_final = string_final.replace('\\n', '')\n",
    "string_final = string_final.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:03:09.673265Z",
     "iopub.status.busy": "2021-07-15T16:03:09.672864Z",
     "iopub.status.idle": "2021-07-15T16:03:09.689488Z",
     "shell.execute_reply": "2021-07-15T16:03:09.688721Z",
     "shell.execute_reply.started": "2021-07-15T16:03:09.673230Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = r'[^a-zA-z0-9\\s]'\n",
    "string_final = re.sub(pattern, \"\", string_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:03:28.046085Z",
     "iopub.status.busy": "2021-07-15T16:03:28.045406Z",
     "iopub.status.idle": "2021-07-15T16:03:28.220820Z",
     "shell.execute_reply": "2021-07-15T16:03:28.220080Z",
     "shell.execute_reply.started": "2021-07-15T16:03:28.046046Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(string_final)\n",
    "tokens = [token.strip() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:06:37.005464Z",
     "iopub.status.busy": "2021-07-15T16:06:37.004886Z",
     "iopub.status.idle": "2021-07-15T16:06:37.018634Z",
     "shell.execute_reply": "2021-07-15T16:06:37.017609Z",
     "shell.execute_reply.started": "2021-07-15T16:06:37.005392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13386"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = Counter(tokens)\n",
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:09:32.952431Z",
     "iopub.status.busy": "2021-07-15T16:09:32.952027Z",
     "iopub.status.idle": "2021-07-15T16:09:32.964215Z",
     "shell.execute_reply": "2021-07-15T16:09:32.963167Z",
     "shell.execute_reply.started": "2021-07-15T16:09:32.952396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u', 951),\n",
       " ('call', 525),\n",
       " ('2', 467),\n",
       " ('ur', 356),\n",
       " ('get', 346),\n",
       " ('im', 344),\n",
       " ('4', 282),\n",
       " ('go', 265),\n",
       " ('ltgt', 244),\n",
       " ('free', 221)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:10:00.676560Z",
     "iopub.status.busy": "2021-07-15T16:10:00.676205Z",
     "iopub.status.idle": "2021-07-15T16:10:00.690071Z",
     "shell.execute_reply": "2021-07-15T16:10:00.689052Z",
     "shell.execute_reply.started": "2021-07-15T16:10:00.676531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u', 'call', '2', 'ur', 'get', 'im', '4', 'go', 'ltgt', 'free']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [x[0] for x in total_words.most_common()]\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:11:37.505891Z",
     "iopub.status.busy": "2021-07-15T16:11:37.505531Z",
     "iopub.status.idle": "2021-07-15T16:11:37.520625Z",
     "shell.execute_reply": "2021-07-15T16:11:37.519469Z",
     "shell.execute_reply.started": "2021-07-15T16:11:37.505860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '008704050406',\n",
       " '0089my',\n",
       " '0121',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '0125698789',\n",
       " '02',\n",
       " '020603',\n",
       " '0207']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_words = list(sorted(words))\n",
    "sorted_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:12:00.070600Z",
     "iopub.status.busy": "2021-07-15T16:12:00.070025Z",
     "iopub.status.idle": "2021-07-15T16:12:00.080402Z",
     "shell.execute_reply": "2021-07-15T16:12:00.079158Z",
     "shell.execute_reply.started": "2021-07-15T16:12:00.070566Z"
    }
   },
   "outputs": [],
   "source": [
    "word_ind = {x: i for i, x in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:12:23.433180Z",
     "iopub.status.busy": "2021-07-15T16:12:23.432637Z",
     "iopub.status.idle": "2021-07-15T16:12:23.436207Z",
     "shell.execute_reply": "2021-07-15T16:12:23.435515Z",
     "shell.execute_reply.started": "2021-07-15T16:12:23.433137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decide on a sentence length\n",
    "sentence_length = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data preparation for modeling</h2>\n",
    "\n",
    "We will be dividing all the data in our text column into sequences of words with fixed length of 10 words (we can modify this according to our requirements). We will be splititng the text based on word sequences, when we create the sequence, we can slide the window across the whole document one word at a time, allowing to learn from its predeceding one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:16:31.123152Z",
     "iopub.status.busy": "2021-07-15T16:16:31.122544Z",
     "iopub.status.idle": "2021-07-15T16:16:31.181321Z",
     "shell.execute_reply": "2021-07-15T16:16:31.180408Z",
     "shell.execute_reply.started": "2021-07-15T16:16:31.123115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare input to output pairs encoded as integers\n",
    "# input - sentence input \n",
    "# output - model output with index\n",
    "inp = []\n",
    "out = []\n",
    "# As we need 11 words (10 words for sentence, 1 for output)\n",
    "# We will set the for loop like this\n",
    "for i in range(0, len(total_words) - sentence_length, 1):\n",
    "    x = tokens[i:i+sentence_length]\n",
    "    y = tokens[i+sentence_length]\n",
    "    # Creating a vector\n",
    "    inp.append([word_ind[char] for char in x])\n",
    "    out.append(word_ind[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:38:24.074590Z",
     "iopub.status.busy": "2021-07-15T16:38:24.074013Z",
     "iopub.status.idle": "2021-07-15T16:38:24.083759Z",
     "shell.execute_reply": "2021-07-15T16:38:24.082848Z",
     "shell.execute_reply.started": "2021-07-15T16:38:24.074559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inverse dictionary\n",
    "inv_dict = dict(map(reversed, word_ind.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:16:44.073022Z",
     "iopub.status.busy": "2021-07-15T16:16:44.072572Z",
     "iopub.status.idle": "2021-07-15T16:16:44.078714Z",
     "shell.execute_reply": "2021-07-15T16:16:44.077789Z",
     "shell.execute_reply.started": "2021-07-15T16:16:44.072992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12832]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our input and output data in numerical format, we can proceed with one-hot encoding the target variables and training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:18:14.246717Z",
     "iopub.status.busy": "2021-07-15T16:18:14.246216Z",
     "iopub.status.idle": "2021-07-15T16:18:14.373224Z",
     "shell.execute_reply": "2021-07-15T16:18:14.372421Z",
     "shell.execute_reply.started": "2021-07-15T16:18:14.246686Z"
    }
   },
   "outputs": [],
   "source": [
    "X = numpy.reshape(inp, (len(inp), sentence_length, 1))\n",
    "# to_categorical for one-hot encoding\n",
    "Y = np_utils.to_categorical(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:18:16.845765Z",
     "iopub.status.busy": "2021-07-15T16:18:16.845242Z",
     "iopub.status.idle": "2021-07-15T16:18:16.852877Z",
     "shell.execute_reply": "2021-07-15T16:18:16.851765Z",
     "shell.execute_reply.started": "2021-07-15T16:18:16.845733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model building</h2>\n",
    "\n",
    "We will be using LSTMs. We are using a single layer with 256 memory units. The model will use a dropout of 0.2. Softmax activation function is used alongside the ADAM optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:19:10.329668Z",
     "iopub.status.busy": "2021-07-15T16:19:10.329300Z",
     "iopub.status.idle": "2021-07-15T16:19:10.643988Z",
     "shell.execute_reply": "2021-07-15T16:19:10.643021Z",
     "shell.execute_reply.started": "2021-07-15T16:19:10.329636Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:19:18.139286Z",
     "iopub.status.busy": "2021-07-15T16:19:18.137224Z",
     "iopub.status.idle": "2021-07-15T16:19:18.144336Z",
     "shell.execute_reply": "2021-07-15T16:19:18.143615Z",
     "shell.execute_reply.started": "2021-07-15T16:19:18.137707Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name_path=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_name_path, monitor='loss',\n",
    "verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** - We have not split the training and testing data here, as we are not interested in the accuracy. Deep learning models require huge amounts of data and time to train, so we will be using all the data we have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:19:24.301243Z",
     "iopub.status.busy": "2021-07-15T16:19:24.300710Z",
     "iopub.status.idle": "2021-07-15T16:20:41.231569Z",
     "shell.execute_reply": "2021-07-15T16:20:41.230502Z",
     "shell.execute_reply.started": "2021-07-15T16:19:24.301194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "105/105 [==============================] - 17s 142ms/step - loss: 8.9770\n",
      "\n",
      "Epoch 00001: loss improved from inf to 8.67458, saving model to weights-improvement-01-8.6746.hdf5\n",
      "Epoch 2/5\n",
      "105/105 [==============================] - 15s 140ms/step - loss: 7.9180\n",
      "\n",
      "Epoch 00002: loss improved from 8.67458 to 8.05159, saving model to weights-improvement-02-8.0516.hdf5\n",
      "Epoch 3/5\n",
      "105/105 [==============================] - 15s 143ms/step - loss: 7.8343\n",
      "\n",
      "Epoch 00003: loss improved from 8.05159 to 7.88771, saving model to weights-improvement-03-7.8877.hdf5\n",
      "Epoch 4/5\n",
      "105/105 [==============================] - 15s 140ms/step - loss: 7.6362\n",
      "\n",
      "Epoch 00004: loss improved from 7.88771 to 7.68709, saving model to weights-improvement-04-7.6871.hdf5\n",
      "Epoch 5/5\n",
      "105/105 [==============================] - 15s 141ms/step - loss: 7.5485\n",
      "\n",
      "Epoch 00005: loss improved from 7.68709 to 7.59327, saving model to weights-improvement-05-7.5933.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd51c2d9350>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=5, batch_size=128, callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generating random input to predict next word</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:40:33.667256Z",
     "iopub.status.busy": "2021-07-15T16:40:33.666759Z",
     "iopub.status.idle": "2021-07-15T16:40:33.673011Z",
     "shell.execute_reply": "2021-07-15T16:40:33.672136Z",
     "shell.execute_reply.started": "2021-07-15T16:40:33.667225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10546"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random sequence\n",
    "rand_val = numpy.random.randint(0, len(inp))\n",
    "rand_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:40:34.120646Z",
     "iopub.status.busy": "2021-07-15T16:40:34.120292Z",
     "iopub.status.idle": "2021-07-15T16:40:34.127097Z",
     "shell.execute_reply": "2021-07-15T16:40:34.126108Z",
     "shell.execute_reply.started": "2021-07-15T16:40:34.120616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6502,\n",
       " 7687,\n",
       " 7925,\n",
       " 4119,\n",
       " 11551,\n",
       " 5122,\n",
       " 13023,\n",
       " 4553,\n",
       " 3612,\n",
       " 1791,\n",
       " 9489,\n",
       " 4555,\n",
       " 5592,\n",
       " 2370,\n",
       " 5434,\n",
       " 644,\n",
       " 11443,\n",
       " 11999,\n",
       " 9649,\n",
       " 8315,\n",
       " 7123,\n",
       " 9943,\n",
       " 7119,\n",
       " 3379,\n",
       " 2182]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = inp[rand_val]\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:40:34.633479Z",
     "iopub.status.busy": "2021-07-15T16:40:34.633146Z",
     "iopub.status.idle": "2021-07-15T16:40:34.637890Z",
     "shell.execute_reply": "2021-07-15T16:40:34.636731Z",
     "shell.execute_reply.started": "2021-07-15T16:40:34.633451Z"
    }
   },
   "outputs": [],
   "source": [
    "X = numpy.reshape(input_sentence, (1, len(input_sentence), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:40:35.205392Z",
     "iopub.status.busy": "2021-07-15T16:40:35.205011Z",
     "iopub.status.idle": "2021-07-15T16:40:35.251791Z",
     "shell.execute_reply": "2021-07-15T16:40:35.250981Z",
     "shell.execute_reply.started": "2021-07-15T16:40:35.205360Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_word = model.predict(X, verbose=0)\n",
    "index = numpy.argmax(predict_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T16:40:38.882374Z",
     "iopub.status.busy": "2021-07-15T16:40:38.881956Z",
     "iopub.status.idle": "2021-07-15T16:40:38.888395Z",
     "shell.execute_reply": "2021-07-15T16:40:38.887485Z",
     "shell.execute_reply.started": "2021-07-15T16:40:38.882342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knowal', 'moan', 'n', 'e', 'thin', 'goes', 'wrong', 'faultal', 'de', 'arguments', 'r', 'faultfed', 'himso', 'bother', 'hav', '2go', 'thanxxxneft', 'transaction', 'reference', 'number', 'ltgt', 'rs', 'ltdecimalgt', 'credited', 'beneficiary']\n",
      "\n",
      "\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "result = inv_dict[index]\n",
    "sent_in = [inv_dict[value] for value in input_sentence]\n",
    "print(sent_in)\n",
    "print (\"\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, given the 25 input words, it's predicting the word “u” as the next\n",
    "word. Of course, its not making much sense, since it has been trained on\n",
    "much less data and epochs. Make sure you have great computation power\n",
    "and train on huge data with high number of epochs.\n",
    "\n",
    "Through this, we were successful in creating a model that can predict the next word based on a given sequence. This can further be improved with much larger corpus of text and bigger networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
